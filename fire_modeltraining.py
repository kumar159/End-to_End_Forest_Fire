# # -*- coding: utf-8 -*-
# """Fire_ModelTraining.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/13H-MCCLWOnE9eBeR7B1qdM7_zRmFaff0
# """

# # Commented out IPython magic to ensure Python compatibility.
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# # %matplotlib inline

# df = pd.read_csv('/content/Cleaned_Algerian_forest_fires_dataset.csv')
# df.head()

# df = df.drop('index', axis=1)
# df.head()

# df = df.drop(['day', 'month', 'year'], axis=1)
# df.head()

# df['Classes'].value_counts()

# df['Classes'] = df['Classes'].replace({'fire': '1', 'not fire':0})
# df['Classes'].value_counts()

# """Training"""

# # independent feature and dependent feature
# X = df.iloc[:, :9]
# y = df['FWI']

# X.head()

# y

# # Train-Test split
# from sklearn.model_selection import train_test_split

# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# X_train.shape

# X_test.shape

# # Feature selection based on correlation
# df.corr()

# # check for multi-collinearity
# plt.figure(figsize=(12, 10))
# sns.heatmap(X_train.corr(), annot=True)

# def correlation(dataset, threshold):
#     col_corr = set()
#     corr_matrix = dataset.corr()
#     for i in range(len(corr_matrix.columns)):
#         for j in range(i):
#             if abs(corr_matrix.iloc[i, j]) > threshold:
#                 colname = corr_matrix.columns[i]
#                 col_corr.add(colname)
#     return col_corr

# ## threshold--Domain expertise
# corr_features=correlation(X_train,0.85)

# corr_features

# # drop features whose correlation is > 0.85
# X_train.drop(corr_features, axis=1, inplace=True)
# X_test.drop(corr_features, axis=1, inplace=True)
# X_train.shape, X_test.shape

# """Standardization"""

# from sklearn.preprocessing import StandardScaler
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)

# X_train_scaled

# """Box Plot to understand the effect of StandardScaler"""

# plt.subplots(figsize=(15, 5))
# plt.subplot(1, 2, 1)
# sns.boxplot(data=X_train)
# plt.title('X_train Before Scaling')
# plt.subplot(1, 2, 2)
# sns.boxplot(data=X_train_scaled)
# plt.title('X_train After Scaling')

# """Linear Regression Model"""

# from sklearn.linear_model import LinearRegression
# from sklearn.metrics import mean_absolute_error
# from sklearn.metrics import r2_score
# linreg=LinearRegression()
# linreg.fit(X_train_scaled, y_train)
# y_pred = linreg.predict(X_test_scaled)
# mae = mean_absolute_error(y_test, y_pred)
# score = r2_score(y_test, y_pred)
# score=r2_score(y_test,y_pred)
# print("Mean absolute error", mae)
# print("R2 Score", score)
# plt.scatter(y_test, y_pred)

# """Lasso Regression"""

# from sklearn.linear_model import Lasso
# from sklearn.metrics import mean_absolute_error
# from sklearn.metrics import r2_score
# lasso=Lasso()
# lasso.fit(X_train_scaled, y_train)
# y_pred = lasso.predict(X_test_scaled)
# mae = mean_absolute_error(y_test, y_pred)
# score = r2_score(y_test, y_pred)
# score=r2_score(y_test,y_pred)
# print("Mean absolute error", mae)
# print("R2 Score", score)
# plt.scatter(y_test, y_pred)

# from sklearn.linear_model import LassoCV
# lassocv = LassoCV(cv=5)
# lassocv.fit(X_train_scaled, y_train)

# lassocv.alpha_

# lassocv.alphas_

# y_pred=lassocv.predict(X_test_scaled)
# plt.scatter(y_test,y_pred)
# mae=mean_absolute_error(y_test,y_pred)
# score=r2_score(y_test,y_pred)
# print("Mean absolute error", mae)
# print("R2 Score", score)

# from sklearn.linear_model import Ridge
# from sklearn.metrics import mean_absolute_error
# from sklearn.metrics import r2_score
# ridge=Ridge()
# ridge.fit(X_train_scaled,y_train)
# y_pred=ridge.predict(X_test_scaled)
# mae=mean_absolute_error(y_test,y_pred)
# score=r2_score(y_test,y_pred)
# print("Mean absolute error", mae)
# print("R2 Score", score)
# plt.scatter(y_test,y_pred)

# from sklearn.linear_model import RidgeCV
# ridgecv=RidgeCV(cv=5)
# ridgecv.fit(X_train_scaled,y_train)
# y_pred=ridgecv.predict(X_test_scaled)
# plt.scatter(y_test,y_pred)
# mae=mean_absolute_error(y_test,y_pred)
# score=r2_score(y_test,y_pred)
# print("Mean absolute error", mae)
# print("R2 Score", score)

# ridgecv.get_params()

# """Elastic Net"""

# from sklearn.linear_model import ElasticNet
# from sklearn.metrics import mean_absolute_error
# from sklearn.metrics import r2_score
# elastic=ElasticNet()
# elastic.fit(X_train_scaled,y_train)
# y_pred=elastic.predict(X_test_scaled)
# mae=mean_absolute_error(y_test,y_pred)
# score=r2_score(y_test,y_pred)
# print("Mean absolute error", mae)
# print("R2 Score", score)
# plt.scatter(y_test,y_pred)

# from sklearn.linear_model import ElasticNetCV
# elasticcv=ElasticNetCV(cv=5)
# elasticcv.fit(X_train_scaled,y_train)
# y_pred=elasticcv.predict(X_test_scaled)
# plt.scatter(y_test,y_pred)
# mae=mean_absolute_error(y_test,y_pred)
# score=r2_score(y_test,y_pred)
# print("Mean absolute error", mae)
# print("R2 Score", score)

# elasticcv.alphas_

# """Pickle the ml models, preprocessing model StandardScaler"""

# scaler

# ridge

# import pickle
# pickle.dump(scaler, open('scaler.pkl', 'wb'))
# pickle.dump(ridge, open('ridge.pkl', 'wb'))

